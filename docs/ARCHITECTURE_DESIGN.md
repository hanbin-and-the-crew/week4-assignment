# Mission 1: 요구사항 분석 및 아키텍처 설계

각 이해관계자의 요구사항을 구체적인 기술 요구사항으로 전환하는 과정을 정리한 문서입니다.

<details>
<summary><h2>Step 1. 운영팀장 요구사항 분석 – "자동 복구"</h2></summary>

---

### **1) 요구사항의 의미 해석**
운영팀장이 말하는 “자동 복구”는  
**서비스 장애가 발생했을 때 사람이 개입하지 않아도 스스로 정상 상태로 복귀하는 것**을 의미합니다.

즉 다음 두 가지가 핵심입니다:

1. **장애를 자동으로 감지하는가?**  
2. **감지 후 자동으로 정상 상태로 되돌릴 수 있는가?**

운영팀장은 개발자가 아니기 때문에  
“복구가 가능하다 / 불가능하다”를 명확히 나누고,  
각 장애 상황에서 “얼마나 자동화되는지”를 구체적으로 알고 싶어 합니다.

---

### **2) 장애 시나리오 표 작성**

| 장애 시나리오 | 원인 | 자동 복구 가능 여부 | AWS 복구 방식 | 복구 시간 |
|---------------|------|----------------------|----------------|------------|
| App 크래시(OOM) | 메모리 누수, Xmx 부족 | ✅ 가능 | ECS Task 자동 재시작 / Auto Scaling | 약 30초~1분 |
| ECS 호스트 장애 | EC2 하드웨어 문제 | ✅ 가능 | ASG 또는 Fargate 자동 교체 | 약 1~2분 |
| DB 응답 없음 | 프로세스 다운, I/O 문제 | ✅ 가능 | RDS Multi-AZ 자동 Failover | 30~120초 |
| AZ 전체 장애 | 네트워크/장비 장애 | ✅ 가능 | Multi-AZ 자원으로 우회 | 수 분 |
| CrashLoop(Code Bug) | 잘못된 배포/버그 | ❌ 불가 | 롤백 또는 코드 수정 필요 | 사람 개입 필요 |
| DB 디스크 Full | FreeStorageSpace 0% | ❌ 부분적 | 자동확장 가능 시 자동, 아니면 수동 처리 | 사람 개입 필요 |
| 리전 장애 | AWS 리전 전체 문제 | ❌ 불가 | DR 리전으로 전환 | 사람 개입 필요 |

---

###  3) 비기술자를 위한 설명 

1. **시스템은 스스로 건강 상태를 감시합니다.**  
   30초마다 심장박동처럼 스스로를 체크합니다.

2. **오류가 일정 횟수 이상 반복되면 자동으로 복구합니다.**  
   - 앱이 멈추면 → 다시 켭니다  
   - 서버가 죽으면 → 새 서버를 띄웁니다  
   - DB가 멈추면 → 대기 중이던 DB로 자동 전환합니다

3. **자동 복구가 가능한 장애와 그렇지 않은 장애를 구분해야 합니다.**  
   - 서버나 앱이 멈추는 문제 → 자동 복구 가능  
   - 코드 자체가 잘못되었거나 DB가 꽉 찬 문제 → 사람 개입 필요

4. **자동 복구는 보통 30초~2분 사이에 이루어집니다.**  
   대부분의 장애는 운영팀이 오기 전에 시스템이 먼저 해결합니다.

---

### 4) 참고 다이어그램

(문서 완성 시 노션/슬라이드에서 이미지 삽입)

---

<details>
<summary><h3>탐구 질문</h3></summary>

### 1-1. 애플리케이션이 OutOfMemoryError로 크래시되는 경우는 어떻게 감지하고 복구할 수 있나요?

- 원인:
    - 컨테이너에 할당한 메모리보다 프로세스가 더 많은 메모리 사용, 메모리 누수
    - JVM Xmx 제한 misconfig
- 감지:
    - ECS 콘솔에서 중지된 작업을 확인하거나 Health Check 실패시
    - **CloudWatch** 메트릭으로 컨테이너 메모리 사용률, Task/Service 오류 증가 확인
    - **EventBridge** 룰로 stoppedReason/ Exit Code 137(SIGKILL, 강제 종료), 139(SIGSEGV, Segmentation Fault) 종료 코드를 잡고 이벤트 처리
- 복구 및 대응:
    - ECS Service Scheduler가 실패한 Task를 종료하고 동일 TaskDefinition으로 새로운 Task 재시작
    - Auto Scaling을 이용하여 메모리 사용률 기반으로 자동 확장 (예: MemoryUtilization > 70%)
- 용어 정리:
    - **CloudWatch**: AWS 리소스와 AWS에서 실시간으로 실행 중인 애플리케이션을 모니터링 하는 서비스
    - **EventBridge**: AWS의 리소스 상태 변화나 스케줄링(특정 시간)에 따라 작업을 실행할 수 있는 서비스, AWS 서비스에 대한 이벤트 감지 후 라우팅을 수행한다.
- `요구사항에 따른 우리 아키텍처 설명`:
    - 애플리케이션이 메모리 부족으로 비정상 종료되면, CloudWatch가 메모리 사용률 등으로 즉시 이를 감지하여 모니터링 대시보드에 알람을 전송합니다. 동시에 ECS 서비스 스케줄러가 자동으로 작동하여 문제가 발생한 컨테이너를 종료하고, 동일한 설정으로 새로운 컨테이너를 시작합니다. 만약 메모리 사용률이 지속적으로 70%를 초과하면, Auto Scaling이 자동으로 추가 컨테이너를 생성하여 부하를 분산시킵니다. 전체 복구 과정은 약 30초~1분 내에 자동으로 완료되며, 사람의 개입 없이 자동으로 진행됩니다.

---

### 1-2. ECS Task가 실행 중인 물리 호스트에 하드웨어 문제가 생긴다면?

- 원인:
    - EC2 호스트 장애, 커널 패닉, Docker 데몬 문제, Disk I/O failure
- 감지:
    - ECS에서 해당 인스턴스에 있는 모든 Task가 STOPPED 또는 DRAINING 상태로 바뀜.
    - **CloudWatch**에서 `StatusCheckFailed_System` 또는 ASG/EC2 상태 알람. AWS가 호스트 장애를 감지하면 시스템 상태 check fail가 발생
- 복구 및 대응:
    - **EC2 Auto Recovery**: EC2의 `automatic instance recovery` 설정이 켜져 있으면 AWS가 인스턴스를 다른 하드웨어로 복구(마이그레이션) 시도
    - **ECS + Multi-AZ / ASG 조합**: ASG가 있다면 Auto Scaling이 다른 AZ/호스트에 새로운 인스턴스로 보충. ECS Fargate면 호스트 책임이 AWS에 있으므로 서비스가 더 빨리되는 편이다.
- 개념 정리:
    - AWS EC2에는 상태 체크는 2가지가 존재한다.
    - **System Status Check**(AWS 책임영역) → 문제 발생시 `StatusCheckFailed_System`
    - **Instance Status Check**(사용자 책임 영역) → 문제 발생시 `StatusCheckFailed_Instance`
- `요구사항에 따른 우리 아키텍처 설명`:
    - 시스템이 30초마다 스스로 건강 상태를 확인합니다. 만약 3번 연속으로 응답하지 않으면, 문제가 있다고 판단하고 자동으로 해당 컨테이너를 종료한 후 새로운 컨테이너를 시작합니다. 전체 과정은 약 1분 정도 걸리며, 사람의 개입 없이 자동으로 진행됩니다.

---

### 1-3. 데이터베이스가 응답하지 않는다면 애플리케이션은 어떻게 되나요?

- 원인:
    - DB 프로세스 크래시, 스토리지 I/O 문제, 디스크가 가득 참, 데드락 등등
- 감지:
    - CloudWatch `DatabaseConnections`/`CPUUtilization`/`FreeStorageSpace` 알람
    - RDS 이벤트(AWS Health) 알람
    - 애플리케이션 DB 타임아웃/예외 급증, RDS 콘솔의 인스턴스 상태 등 RDS 이벤트 구독
- 복구 및 대응:
    - **RDS Multi-AZ**: Primary 장애 감지 시 Standby를 **자동 승격**(failover)한다. 보통 30~120초의 소모시간이 걸리며, 애플리케이션은 동일한 엔드포인트로 재연결하며 복구된다
    - 가능하다면 RDS Storage Auto Scaling 이용
    - 어플리케이션 레벨에서는 Spring의 경우 `Resilience4j`와 같은 라이브러리를 이용함으로써 서킷 브레이커 패턴 구현하여 장애가 발생한 네트워크 및 DB에 추가적인 요청 차단
- `요구사항에 따른 우리 아키텍처 설명`:
    - CloudWatch에서 DB의 연결 수가 갑자기 0이 되거나 반대로 연결 시도 수가 최대치까지 올라가게 되면 DB가 응답하지 않다고 판단합니다. 이를 대비하여 RDS를 여러 가용영역에서 미리 정의하며 장애 판단이 확정되었을 경우 스탠바이 데이터베이스로 자동으로 승격 및 전환을 시키게 됩니다. 전체 과정은 약 30초~2분 정도 걸리며, 사람의 개입 없이 자동으로 진행됩니다.

---

### 1-4. 한 가용영역(AZ) 전체에 장애가 발생하는 극단적인 상황에서는?

- 원인:
    - 매우 드물지만 AZ 자체의 인프라 장애, 네트워크 스위치 등 장비 문제
- 감지:
    - ALB Target Health가 특정 AZ의 모든 Target이 UNHEALTHY
    - 특정 AZ에 배포된 리소스(EC2, ECS task, RDS standby 등)의 상태 급변
    - CloudWatch에서 AZ별 트래픽 급감
- 복구 및 대응:
    - **Multi-AZ 설계**: 다른 AZ의 리소스(Standby RDS, EC2 인스턴스, ECS Task)로 트래픽이 자동 라우팅/스케줄링 되어 다운타임을 줄일 수 있다. ASG는 다른 AZ에 인스턴스를 자동 생성하며 RDS는 standby 승격시킨다.
    - **Cross-Region DR**: 금융권·대형 서비스 등의 경우 리전 장애까지 고려하여 타 Region에서 복구하도록 설계
- `요구사항에 따른 우리 아키텍처 설명`:
    - 로드밸런서가 특정 가용영역이나 네트워크에 보내는 모든 건강 신호가 비정상일 경우 가용영역에 장애가 발생하였다고 판단하며 다른 가용영역의 EC2나 데이터베이스로 전환을 시도합니다. 전체 과정은 수분 정도 걸리며, 사람의 개입 없이 자동으로 진행됩니다.

---

## 2. AWS 자동 복구 기능 조사

### 2-1. ECS Health Check는 어떤 방식으로 Task의 건강 상태를 판단하나요?

- **ALB(Target Group) Health Check**: ALB가 설정된 HTTP(S) 요청(예: `/health`)을 주기적으로 보냄.  
  실패 시 Unhealthy 처리  
    ```
    Health Check Path: /actuator/health
    Healthy Threshold: 2
    Unhealthy Threshold: 2
    Interval: 25초
    ```

- ECS 컨테이너 Health Check** (Docker HEALTHCHECK)  
  실패 시 ECS가 Task 교체  
    ```
    "healthCheck": {
      "command": ["CMD-SHELL", "curl -f http://localhost:8080/actuator/health || exit 1"],
      "interval": 25,
      "timeout": 5,
      "retries": 3,
      "startPeriod": 60
    }
    ```

- Health Check Grace Period
  Task 시작 시 초기화 시간 동안 헬스체크 미적용  
    ```
    health_check_grace_period_seconds = 300
    ```

---

### **2-2. Health Check가 실패하면 정확히 무슨 일이 일어나나요?**

- ALB → 타겟을 Unhealthy로 표시  
- ALB → 해당 ECS Task로 트래픽 중단  
- ECS → Desired Count 유지 위해 새로운 Task 자동 생성  
- 컨테이너 HealthCheck 실패도 동일하게 UNHEALTHY 처리

---

### **2-3. Multi-AZ 배포는 왜 필요하고, Single-AZ와 비교했을 때 어떤 장점과 단점이 있나요?**

- 장점  
    - AZ 장애 보호  
    - 트래픽 분산  
- 단점  
    - 비용 증가  
    - 구조 복잡성 증가  
- 결론: 서비스가 커질수록 반드시 필요

---

### **2-4. RDS의 자동 Failover는 어떻게 작동하며, 얼마나 시간이 걸리나요?**

- Primary 장애 시 Standby → Primary 승격  
- 클라이언트는 동일 엔드포인트로 재접속  
- 소요시간: **30초~120초**

---

### **2-5. Auto Scaling은 "자동 복구"인가요, 아니면 "자동 확장"인가요?**

- 자동 확장: CPU/메모리/큐 기준으로 확장  
- 자동 복구: Unhealthy 인스턴스를 신규 인스턴스로 대체  
- 두 기능 모두 ASG 기반

---

## **3. 자동 복구 불가능한 경우**

### **3-1. 애플리케이션 코드 버그로 Task가 CrashLoop일 때**

- ECS가 무한 재시작  
- AWS로는 해결 불가  
- 해결: 코드 수정 → 재배포  
- Deployment Circuit Breaker로 자동 롤백 가능

---

### **3-2. 데이터베이스 디스크가 가득 찬 경우**

- 문제: FreeStorageSpace 0% → 트랜잭션 실패  
- 대응: 알람 → 로그 정리 → Storage Auto Scaling(가능 시)

---

### **3-3. 드물지만 AWS 리전 전체 장애**

- Multi-AZ도 보호 불가  
- Cross-Region DR 구축 필요  
- 사람 개입 필수

---


</details>

---

</details>

<details>
<summary><h2>step2 비즈니스팀장 요구사항 분석 - "Auto Scaling"</h2></summary>
  
## **1. Auto Scaling 트리거 선택**

| 트리거 | 장점 | 단점 | SwiftLogix 적합성 |
| --- | --- | --- | --- |
| CPU 사용률 70% 초과 | 가장 일반적, 구현 용이 | CPU가 높다고 항상 느린 것은 아님(비동기, 동기 작업 비율이 중요) | 보조 지표로 적합 |
| 메모리 사용률 80% 초과 | OutOfMemory 방지 가능, 치명적 장애 예방 | 측정 복잡, 일부 서비스에서는 정확치 않음 | 중요하지만 단독 지표로는 부족 |
| HTTP 요청 큐 길이 | 실제 처리 능력 직접 반영 | 모니터링 구현 필요, 큐 길이 지표는 설정이 조금 더 복잡함 | **주요 지표로 적합**, 특히 SwiftLogix처럼 웹 요청 중심 |
| 응답시간 95 백분위수 800ms 초과 | SLA 위반 직전 신호, 사용자 경험 직결 | 이미 느려진 상태, 늦은 대응(사후 대응) | 모니터링용. 보조 지표로 유용 |

**추천:**

- SwiftLogix는 웹 요청 기반 서비스라서 **HTTP 요청 큐 길이**가 가장 직접적인 트리거.
- CPU, 메모리 초과 지표는 **보조 지표**로 두어 이상 상황 시 경고나 추가 이벤트 발생으로 처리한다.

 응답시간은 늦은 대응이기 때문에 단순 알람용으로 이용한다.

## **2. Task 개수 범위 설정**

### **1) 최소 Task 계산:**

- 평상시 트래픽: 20 req/sec
- 일반적인 Spring 기반 API 기준 1 Task ≈ 초당 30~50 req 처리 가능하니 대략 40 req/s라 고려
- 즉, 하나의 Task로 평상시 트래픽까지는 충분히 버틸 수 있다.

### **2) 여유분 고려:**

- 고가용성 및 갑작스러운 트래픽 증가 대비 +1~2 Task 확보
- 따라서 여유분까지 고려하면 `최소 2개의 Task`는 있는게 안정적이다.

### **3) 최대 Task 계산:**

- 블랙프라이데이 예상 트래픽: 200 req/sec
- 한 Task 40 req/sec → 200 ÷ 40 = 5 Task 필요
- 피크 상황에서는 스파이크가 발생하므로 버퍼 40% 고려 5 x 1.4 = 7개
- 따라서 `Max Task는 7~9개`가 적절하다
- Auto Scaling 한 번에 늘리는 단위는
    - 비용 절감: 1개씩 점진적 확장
    - 빠른 대응: 한번에 2~4개씩 확장
    - 블랙프라이데이처럼 예상 트래픽이 많으면 **Scheduled Scaling + Warm Pool** 사용

### **3. 블랙프라이데이 대응 전략**

| 전략 | 장점 | 단점 | SwiftLogix 적합성 |
| --- | --- | --- | --- |
| 반응적 Auto Scaling | 평상시 비용 절감 | Task 시작 지연으로 과부하 발생 가능 | 런칭 초반에만 사용 |
| Scheduled Scaling | 미리 Task 확보 가능 | 트래픽 예상치 필요 | 블랙프라이데이, 프로모션 대응에 최적 |
| Warm Pool | 즉시 활성화 가능 | 관리 복잡, 기본 비용 발생 | 블랙프라이데이와 같이 시간 예측 가능할 때 유용 |
- Scheduled Scaling: `블랙프라이데이 오전 9시에 Task 10개 자동 확보`처럼 비용은 '그 시간대'에만 증가하기 때문에 100% 예측 가능한 이벤트에 최적
- Warm Pool: 컨테이너/EC2를 기동만 해놓고 Idle 상태로 두었다가 즉시 활성화하는 방식으로 기본 비용이 발생하긴 하지만 예측하지 못한 이벤트에도 어느 정도 대응 가능

### **추천:**

- **런칭 전/초반:** 반응적 Auto Scaling으로 모니터링 및 안정화
- **블랙프라이데이:** Scheduled Scaling + Warm Pool 병행을 목표로 한다. 하지만 Warm Pool은 방식이 복잡하기 때문에 처음에는 Scheduled Scaling을 이용하여 대응하다가 부족할 경우 늘리는 방식 이용

### **4. 현실적 우선순위 판단**

| 시기 | 우선순위 | 작업 |
| --- | --- | --- |
| **런칭 전 (72시간)** | 필수 | Multi-AZ 배포, 최소 Task 2개 이상, 수동 Task 조정 구조 확보, CloudWatch 모니터링 시작 |
| **런칭 후 1~2주** |  나중 | 실제 트래픽 데이터 수집, CPU/메모리/응답시간 패턴 분석, Auto Scaling 정책 최종 설계, 블랙프라이데이 대비 시뮬레이션 |

### **핵심:**

- 72시간은 매우 촉박한 시간이기 때문에 `최소 기능 + 최대 안정성`을 우선순위로 잡았다.
- **런칭 전:** 안정적인 서비스 운영이 목표 → Task 여유분까지 확보 및 Multi-AZ 이용
- **런칭 후:** 데이터 기반 확장 정책 수립 → Auto Scaling 적용

### **정리:**

1. 주요 Auto Scaling 트리거: HTTP 요청 큐 길이, 보조 지표: CPU/메모리
2. 최소(평소) Task 2개 ~ 최대 Task 7~9개(블랙프라이데이)
3. 블랙프라이데이: Scheduled Scaling + Warm Pool 고려
4. 런칭 전 72시간: 안정성 확보 우선, 런칭 후 1~2주: 데이터 기반 Auto Scaling 정책 설계

| 단계 | 시기 | 목표 | 구현 내용 |
| --- | --- | --- | --- |
| 1단계 | 72시간 전 | 최소 기능 구현 | Multi-AZ 배포, 최소 Task 2개 이상, 수동 Task 조정 구조 확보 |
| 2단계 | 지금(런칭) | 안정적 서비스 시작 | CloudWatch 모니터링 시작 |
| 3단계 | 1주 후 | 데이터 수집 | 실제 트래픽 데이터 수집, CPU/메모리/응답시간 패턴 분석 |
| 3단계 | 1~2주 후 | 자동 확장 | Auto Scaling 정책 최종 설계 및 부하 테스트 |
| 3단계 | 2주 후 | 블락프라이데이 대비 | Scheduled Scaling + Warm Pool 정책 설계 |

## **비즈니스 팀장 설득**

비즈니스 팀장님! 지금 출시 시점의 경우 당장 Auto Scaling은 작동하지 않습니다. 자동 복구의 핵심이기도 하며 서비스 규모가 커질수록 없어서는 안 될 존재이지만, 현재 상황을 토대로 계획을 설명드리겠습니다.

우선 출시가 72시간 남은 긴급한 상황인만큼 최소 기능과 최대 안정성을 고려하여 설계 우선순위를 계획하였습니다. Multi-AZ 배포, 최소 Task 2개 이상, 수동 Task 조정 구조 확보와 같이 Auto Scaling을 적용하기 위한 밑바탕이 되는 작업들은 전부 수행하였지만, 어떻게 수행할 것인가?는 아직 정해지지 않았습니다. 

HTTP 요청 큐 길이를 메인 트리거로 이용할 것이기 때문에 어떻게, 얼마나 트래픽 데이터가 발생하는지, 그에 따른 로그 데이터가 어떻게 이루어지는지도 확인해봐야 할 것입니다. 이는 출시 직후보다 2주 정도 데이터가 쌓인 다음 분석하여 Auto Scaling을 적용하는 것이 낫다고 판단되었습니다.

따라서 현재는 서비스가 잘 돌아가는지를 우선적으로 기능 구현하며, Cloudwatch로 모니터링하거나 로그 데이터를 분석한 이후 Auto Scaling을 적용할 예정입니다. 그와 더불어 블랙프라이데이같은 트래픽이 몰리는 경우에서도 작동할 수 있게 설계하기 위해 Scheduled Scaling 정책처럼 준비할 것이며, Warm Pool 방식까지 고려 중에 있음을 이렇게 알려드립니다!

</details>

<details>
<summary><h2>step3 DB 격리 - 네트워크 격리와 심층 방어</h2></summary>

## **네트워크 다이어그램**

<img width="842" height="1090" alt="image" src="https://github.com/user-attachments/assets/9c5d445c-689e-4727-ad8e-95bd3b10d5e0" />

## **Security Group 관계**

<img width="1013" height="552" alt="image" src="https://github.com/user-attachments/assets/693147d2-d38a-4b77-9990-1693f6f89ebe" />


## **Defense in Depth (심층 방어) 전략 설명**

**전략 요약** 

| 계층 | 방어 요소 | 내용 |
| --- | --- | --- |
| **1층** | VPC 고립 | AWS 내부에서 완전 격리된 네트워크 |
| **2층** | Subnet 분리 | Public / Private / DB 계층 분리 |
| **3층** | Route Table 통제 | IGW·NAT·Local Only 구조로 트래픽 방향 제어 |
| **4층** | Security Group | 최소 권한 기반 화이트리스트 방화벽 |
| **5층** | Bastion Host | 운영자 접근 단일화 및 강력한 접근 통제 |
| **6층** | DB 사용자 권한 최소화 | DROP/ALTER 등 위험 명령 차단 |
| **7층** | CloudWatch Logs | 애플리케이션/시스템 로그 감시 |

**상세 내용** 

### **1층 방어: VPC 고립**

AWS 내부에서 완전히 분리된 독립 네트워크 생성

- **IPv4 CIDR → 10.0.0.0/16**
    
    → 이 범위 안에서만 리소스가 존재하며 **외부에서 스캔·침입 불가**
    
- **IPv6: 미사용**
    
    → 불필요한 글로벌 통신 채널 제거로 보안 강화
    

---

### **2층 방어: Subnet 격리 (3-Tier Separation)**

| 계층 | Subnet | 역할 | 방어 목적 |
| --- | --- | --- | --- |
| Public | 2a/2c | ALB, Bastion | 외부 요청만 처리, 민감 자원 없음 |
| Private App | 2a/2c | ECS Fargate | ECS를 외부에서 직접 호출 불가 |
| DB Subnet | 2a/2c | RDS | 인터넷 100% 차단, 랜섬웨어·스캔 공격 원천 차단 |

 공개 계층 / 내부 서비스 계층 / 데이터 계층을 완전히 분리해 공격자가 내부 시스템에서 내부로 퍼져나가는 경우를 차단 (수평적 확산을 차단)

---

### **3층 방어: Route Table을 통한 네트워크 경로 통제**

| Subnet | Route | 목적 |
| --- | --- | --- |
| Public | IGW  | ALB·Bastion만 외부와 통신 |
| Private | NAT Gateway (Outbound Only) | ECS는 나가기만 가능, 외부에서 접근 불가 |
| DB | Local Only | 인터넷 연결 없음  |

 오직 허용된 경로로만 트래픽이 이동하도록 강제하는 네트워크 레벨 방화벽

---

### **4층 방어: Security Group 방화벽**

**화이트리스트 기반 최소 권한 정책** 

**포트·소스 단위까지 최소 권한만 허용하는 애플리케이션 단계 방어**

| SG | 인바운드 | 아웃바운드 | 방어 목적 |
| --- | --- | --- | --- |
| **ALB-SG** | 80/443 → 0.0.0.0/0 | ALL | 외부 요청을 받아 ECS로 전달 |
| **ECS-SG** | 서비스 포트 → ALB-SG | ALL (NAT) | ALB만 ECS에 접근 가능, 외부 차단 |
| **RDS-SG** | 5432 → ECS-SG, Bastion-SG | ALL | DB는 App/Bastion 외 접근 불가  |
| **Bastion-SG** | 22 → 사내IP /32 | 3306 → RDS | 운영자만 DB 점검 가능 |

---

### **5층 방어: Bastion Host (운영자 접근 통제)**

- RDS가 Private/DB Subnet 내부에 있어 직접 접근 불가
- 오직 Bastion EC2 → RDS 로만 접근 허용
- Bastion 접속도 사내 **IP /32**로만 제한
- SSH Key 인증 사용

**운영자 접근 경로를 단일화하여 내부 침입 위험 감소
RDS에 직접 포트 개방 없이 안전한 운영 가능**

---

### **6층 방어: 데이터베이스 권한 최소화**

DB 사용자(app_user):

- 허용: **SELECT / INSERT / UPDATE / DELETE**
- 금지:
    - DROP TABLE
    - ALTER
    - CREATE
    - SUPER 권한

 만약 ECS가 해킹 당해도 DB를 파괴하거나 구조 변경 불가

---

### **7층 방어: CloudWatch Logs · VPC Flow Logs 기반 감사(Audit) & 모니터링**

### **CloudWatch Logs**

ECS/Fargate 로그 저장

- API 요청 기록
- 에러 로그 저장
- 비정상 패턴 감지

---

## **Security Group 규칙 표**

| SG 이름 | 방향 | 프로토콜 | 포트 | Source/Destination | 용도 |
| --- | --- | --- | --- | --- | --- |
| **ALB-SG** | Inbound | TCP | 80 | 0.0.0.0/0 | 인터넷에서 HTTP |
| **ALB-SG** | Inbound | TCP | 443 | 0.0.0.0/0 | 인터넷에서 HTTPS |
| **ECS-SG** | Inbound | TCP | 19505 | ALB-SG | ALB에서만 접근 (주문 서비스 포트) |
| **RDS-SG** | Inbound | TCP | 5432 | ECS-SG | ECS Tasks에서만 DB 접근 |
| **RDS-SG** | Inbound | TCP | 5432 | Bastion-SG | Bastion에서만 DB 접속 허용 |
| **Bastion-SG** | Inbound | TCP | 22 | (사내 IP)/32 | SSH 접근 허용 (운영자만 접속) |



</details>

<details>
<summary><h2>step4 재무팀장 요구사항 분석 - "예산 월 15만원"</h2></summary>

  ### **ECS Fargate 비용**

- ECS 구성
    - 최소 : 2*3 = 6 (서비스 3개 × Task 최소 2개 = 6개 기준)
    - 최대 : 스케일 아웃 계산 "최대 Tasks
    - Task의 최소 2개 기준
        - **트래픽 요구사항 ( 시간대별 동시 사용자 & RPS)**
            
            
            | 시간대 | 동시 사용자 | 초당 요청(RPS) | 비고 |
            | --- | --- | --- | --- |
            | **업무시간 (09–18시)** | 100명 | **20 req/s** | 주문 조회 위주, 주문 생성 2–3건/s |
            | **점심시간 (12–13시)** | 20명 | **5 req/s** | 트래픽 급감 |
            | **야간 (18–익일 09시)** | 5명 | **<1 req/s** | 거의 없음 |
            | **블랙프라이데이 피크** | **1,000명** | **200 req/s** | 다음 달 예정, 반드시 자동 스케일링 필요 |
            
            <details>
            <summary><h3>▶ Task 상세 계산 (시간대별 RPS → Task 수 → 비용 근거)</h3></summary>
              
            계산 방식
            
            ```
            필요 Task 수 = (해당 시간대 RPS / 1 Task 처리량) + 여유분
            여유분 = 고가용성(HA) + 버스트 대응 → +1 또는 +2
            ```
            
            - 상세 계산
                
                ### 시간대별 Task 요구량 계산
                
                ### 업무시간(09–18시): 20 req/s
                
                | 항목 | 값 |
                | --- | --- |
                | 필요한 Task = 20 ÷ 20 = **1개** |  |
                | 고가용성(각기 다른 AZ 배치) | +1 |
                | **권장 최소 Task 수** | **2개** |
                
                → 정상 운영 최소 구성으로 적합.
                
                ---
                
                ### 점심시간(12–13시): 5 req/s
                
                | 항목 | 값 |
                | --- | --- |
                | 필요한 Task = 5 ÷ 20 = **0.25개** |  |
                | 최소 실행 단위 = 1개 |  |
                | 고가용성 | +1 |
                | **권장 Task 수** | 2개 |
                
                → 부하가 적어도 **2개 유지(고가용성 목적)**
                
                ---
                
                ### 야간(18–09시): <1 req/s
                
                | 항목 | 값 |
                | --- | --- |
                | 필요한 Task = 1 ÷ 20 = 0.05개 |  |
                | 하지만 AZ 2개 유지 필요 | 최소 2개 |
                | **권장 Task 수** | 2개 |
                
                → 야간이라고 1개로 줄이면 고가용성 깨짐.
                
                ---
                
                ### 블랙프라이데이 피크: 200 req/s
                
                | 항목 | 계산값 |
                | --- | --- |
                | 필요한 Task = 200 ÷ 20 = **10개** |  |
                | AZ 분산 + 장애 대비 여유분 | +2~4개 |
                | **권장 최대 Task 수** | **12~14개** |
                
                → 안정적으로 처리하려면 12~14개 필요.
                
                (특히 주문 생성이 많아지는 시간대에는 DB I/O 병목이 예상됨)
                
            
            요약 
            
            | 시간대 | RPS | 필요한 Task | 여유 포함 권장 Task |
            | --- | --- | --- | --- |
            | **업무시간** | 20 req/s | 1 | **2개** |
            | **점심시간** | 5 req/s | 0.25 | **2개** |
            | **야간** | <1 req/s | 0.05 | **2개** |
            | **블랙프라이데이 피크** | 200 req/s | 10 | **12~14개** |


            </details>

    - **할당된 vCPU의 크기**(0.25vCPU와 16vCPU 사이의 크기 입력) **: 0.5 vCPU**
    - Task 1개가 **20RPS를 안정적으로 처리**할 수 있어야하며 이 기준을 토대로 Fargate 스펙을 산정
    
    | 인스턴스 | (1초당)평균 처리량 |
    | --- | --- |
    | 0.25 vCPU | 5~8 RPS |
    | 0.5 vCPU | 10~20 RPS |
    | 1 vCPU | 25~40 RPS |
    | 2 vCPU | 50~80 RPS |
    - **결과 요약**
    
    | 항목 | 값 |
    | --- | --- |
    | OS | Linux |
    | CPU Architecture | x86 |
    | Number of Tasks | 6 |
    | Average Duration | 730 hours |
    | **Task vCPU** | **0.5 vCPU** |
    | **Task Memory** | **1 GB** |
    | **Ephemeral Storage** | **20 GB** |
- vCPU: 6 tasks × 0.5 vCPU × $0.04048/vCPU/hour × 730 hours = 88.66 USD
- Memory: 6 tasks × 1GB × $0.004445/GB/hour × 730 hours = 19.48 USD
- Ephemeral Storage: 20GB은 기본적으로 무료
- 총합 `108.1 USD`

 ---
 
 ### **RDS PostgreSQL 비용:**

- RDS 구성
    - DB 인스턴스 수 = 2개 (멀티-AZ)
    - 인스턴스 타입: db.t3.micro (스타트업 첫 계약 상황, 비용 절감 목적으로 가볍게)
    - 온디맨드 100%
    - 프록시는 아직 사용하지 않음.
    - 스토리지: gp3(gp2에 비해 최신버전), 20GB 적당한 성능
    - CloudWatch: 모니터링과 보안, 장애 관리를 위해 + SLA 설명에 필요한 근거를 위해 + AutoScaling 전환 데이터를 위해 사용
    - RDS 성능 개선 도우미(Performance Insight)는 프리티어로 7일 무료 사용
    - 백업 스토리지는 아직 사용하지 않음.
- db.t3.micro Single-AZ: $0.018/hour × 730 hours = 13.14 USD
- db.t3.micro Multi-AZ: Single-AZ × 2 = 26.28 USD
- gp3 스토리지 20GB: $0.115/GB/month × 20GB = (앞에 고쳐야함) 2.30 USD
- 백업 스토리지는 DB 크기와 동일하게 무료
- CloudWatch: 1 instances x 2 vCPU x 730 hours in a month x 0.0125 USD = 18.25 USD
- 싱글 AZ를 선택할 것이며 총합 13.14+2.30+18.25 = `33.69 USD`

 ---

 
 ### **NAT Gateway 비용:**

- Site-to-Site 사용하지 않음
- Client VPN도 사용하지 않음
- 고정 비용: $0.045/hour × 730 hours = 32.85 USD
- Multi-AZ일 경우: 32.85 USD x 2(AZ) = 65.70 USD
- 하루 요청수는 607,500 req/day, 한 달 요청수는 18,225,000 req/month
- 평균 응답 크기가 5 KB라 가정하면 한 달 86.9 GB 데이터 전송 발생
- 데이터 전송 비용: $0.045/GB × 87GB =3.92 USD
- 멀티 az(2)의 경우 월별 73.54 USD
- 싱글 az(1)의 경우 월별 `36.77 USD`

 ---

 
 ### **로드밸런싱용 ELB 비용**:

- ALB 고정 비용: 1 load balancers x $0.0225/hour x 730 hours = 16.43 USD
- 요구사항에 9시간동안 20req/s + 나머지는 1req/s (점심시간 별도 계산)이므로 하루 평균 7.5req/s
- 7.50 new connections/seconds / 25 new connections/seconds/LCU = 0.30 new connections LCUs
- LCU 비용: 1 load balancers x 0.30 LCUs x $0.008 LCU/hour x 730 hours = 1.75 USD
- 총합 16.43 + 1.76 = `18.18 USD`

 ---

 
 ### **Bastion 서버용 EC2 비용:**

- 관리자용 서버로 EC2중 경량 모델인 t2.nano 이용
- t2.nano: $0.0058/Hour x 730h ****= `4.23 USD`

---

 
 ### **기타 비용:**

- CloudWatch: RDS에서 같이 계산됨
- S3 (Docker 이미지): 미미함, 무시 가능
- EIP, ECR은 배포 구성하면서 추가 계산

---


 ### **AWS Budget 스크린샷:**

<img width="2048" height="610" alt="image" src="https://github.com/user-attachments/assets/719b1461-4ac8-4e14-bacc-8fa179e8e355" />


ECS Fargate는 AWS Budget 상에서는 계산식이 상이하기 때문에 따로 계산하여 더해줬다

RDS와 NAT를 Single-AZ로 계산한다면

총합은 92.87 USD(나머지 비용) +108.1 USD(나머지 비용) = **`200.97 USD` = 261,261원**(1300원 기준)

Single-AZ로 줄였음에도 불구하고 예산 15만원을 초과하게 됩니다.

---


 ### **예산 초과 시 절감 방안**

| 절감 방안 | 절감액 | 기술적 위험 | 비즈니스 영향 | 실행 여부 |
| --- | --- | --- | --- | --- |
| ECS Fargate Task 6개에서 3개까지 줄이기 | ₩70,265 | 모니터링 감소, AZ 장애 시 복구 어려움 | 운영팀장 반대 예상 | ❌ |
| RDS Multi-AZ 포기 | 이미 적용됨
₩43,797 | DB 장애 시 수동 복구 필요 | 자동 복구 불가 | ⚠️ 위험 |
| NAT Gateway 1개만 | 이미 적용됨₩47,801 | AZ 장애 시 Private Subnet 인터넷 불가 | 패치/업데이트 불가 | ⚠️ 위험 |
| (RDS) Cloudwatch 사용 안함 | ₩23,725 | 문제 추적 어려움 | DB 장애시 복구 오래 걸릴 것으로 예상 | ⚠️ 위험 |
| Bastion t2.micro → t2.nano | 이미 적용됨
₩5,499 | 성능 저하 가능성 낮음 | 미미함 | ✅ 가능 |

 ### **재무팀장 설득 논리**

재무팀장님! 현재, 시스템이 초창기이기 때문에 비용이 15만원으로 제한되어진다면 결국 Multi-AZ 기능들을 포기해야 한다고 생각합니다. ECS Fargate Task 6개에 Multi-AZ 기능까지 이용한다면 대강 35만원으로 예산이 크게 오버되기 때문입니다.

대신 저녁 이후에 시간이나 새벽에 장애가 발생시 동일 AZ 내에서 복구가 어려운 경우나 DB 자체의 문제라면 개발자가 직접 야근을 하며 장애를 해결해야하며, 여기에서 야근 수당이 추가로 발생되어집니다. 

한 달에 한 두번이면 몰라도 시스템이 초창기이기 때문에 예상치 못한 장애가 많이 발생할 것으로 생각됩니다. 자동 복구 기능이 제대로 갖추어지지 않는다면 더 많은 야근 수당이 발생할 것이기 때문에 여기에서 시스템 비용과 수동으로 장애 복구를 하는 비용간의 조율이 필요하다고 느껴집니다.

또한, SLA 약정에 따라 매달 25만원의 위약금이 발생할 수 있습니다. 따라서 SLA 약정에 최대한 위배되지 않게 시스템을 최소한으로 구현해야 한다고 생각합니다.

---

 ### **최종 제안**

월 26만원으로 아래처럼 시스템이 구성됩니다.

- ECS 6개 Tasks (3개 운영 + 3개 여유)
- Single-AZ RDS
- 1개 NAT Gateway
- ELB는 ALB 이용
- Cloudwatch 이용 (RDS 금액에 포함)
- Bastion Server용으로 EC2 초경량 모델 이용
- S3, EIP, ECR은 구현하지만 가격은 무시 가능

이 방식은 ECS 서비스마다 각각 여유 서비스가 한 개씩 존재하기 때문에 서버에 문제가 생겨도 다른 서버로의 전환을 자동화하여 복구할 수 있습니다. 대신 Single-AZ용 RDS와 NAT Gateway 방식이기 때문에 AZ 자체에 문제가 발생할 경우 자동 복구가 어려워 직접 뛰어들어 문제를 해결해야 합니다.

시스템이 안정화되고 서비스의 규모가 커져서 예산이 늘어날 경우 Multi-AZ용으로 전환할 계획입니다.

</details>

<details>
<summary><h2>step5 CTO 요구사항 분석 - "SLA 준수"</h2></summary>

### **SLA 요구조건**

- SLA 기준: **95th Percentile < 1초**
- 주문 조회 API(`/api/orders`)는 실제 서비스에서 가장 호출 빈도가 높은 핵심 API로 SLA 검증의 기준이 됨.
- SLA 검증 시 네트워크 왕복 지연, ALB 처리, 애플리케이션 처리, DB 쿼리 시간을 모두 포함해 종합적으로 판단해야 함.

---

### **2. JMeter 실제 부하 테스트 결과**

**📌테스트 환경 요약**

| 항목 | 내용 |
| --- | --- |
| **테스트 도구** | Apache JMeter 5.x |
| **테스트 대상 API** | `GET /api/orders` (주문 조회) |
| **테스트 목적** | SLA 기준(95th < 1초) 만족 여부 검증 |
| **테스트 환경** | Local → Spring Boot Order-Service 단일 컨테이너 |
| **Spring Boot 포트** | 19505 |
| **워밍업 전략** | 1분간 5RPS 기본 워밍업 |
| **부하 시나리오** | 5 → 20 → 50 → 100 RPS 단계적 증가 |
| **테스트 총 시간** | 12분 (워밍업 + 정상부하 + 점진 + 피크) |
| **데이터 준비 방식** | 사전 조회용 데이터 삽입 |
| **결과 산출 기준** | JMeter Summary Report + Aggregate Report |

---

**📌 지표 요약**

| 지표 | 결과 | 의미 |
| --- | --- | --- |
| **Median** | 8ms | 절반 이상이 8ms 이하 |
| **95th Percentile** | **20ms** |  |
| **99th Percentile** | 53ms | 극단값도 안정적 |
| **Max** | 382ms | 최악의 스파이크도 0.38초 |
| **Average** | 10ms | 전체 평균 10ms |
| **Error** | 0% | 모든 요청 성공 |

 **결론:** SLA 기준인 1초를 **95th=20ms**로  **충족 확인**

---

### **3. API 응답 경로별 지연 분석**

JMeter 실측 데이터를 기반으로 “사용자 → AWS → ECS → DB → 사용자” 단계 전체 지연을 계산.

### **응답 경로 지연 분석**

| 경로 단계 | 예상 지연 | 최적화 여부 | 개선 포인트 |
| --- | --- | --- | --- |
| 사용자 → AWS | 20–30ms | ❌ | 지역 기반 라우팅 |
| ALB 처리 | 3–5ms | ❌ | - |
| Spring Boot 처리 | 5–10ms | ✅ | 불필요한 로직 제거 |
| DB 쿼리 | 5–15ms | ✅ | 인덱스 추가, 쿼리 최적화 |
| JSON 직렬화 | 2–3ms | ⚠ | Jackson 옵션 튜닝 |
| AWS → 사용자 | 20–30ms | ❌ | - |
| **총합** | **55~93ms** | - | - |


---

## **4.0.5 vCPU, 1GB 메모리를 선택 근거**

---

### **1. 실측 성능 기반 스펙 산정**

- JMeter 테스트 결과 **평균 10ms**, **95th Percentile 20ms**
- Task 1개 기준 처리 가능량:
    
    ```
    1000ms / 10ms = 100RPS (이론)
    → 네트워크·부하 반영 후 실제 안정 처리량 = 20 RPS
    
    ```
    
- 즉, **0.5 vCPU 1개 Task로 20RPS 안정적으로 처리 가능**

---

### **2. 서비스당 최소 2개 Task로 평시 트래픽을 충분히 감당**

- 평시 트래픽: **20RPS**
- Task 2개 처리량: **40RPS**
    
    → 평소 트래픽의 **2배 여유**
    
- 또한, AZ 분산(고가용성)까지 만족하는 최소 구성

---

### **3. 비용 대비 성능 최적점이 0.5 vCPU**

| vCPU | 평균 처리량 | 적합 여부 |
| --- | --- | --- |
| 0.25 vCPU | 5~8 RPS | ❌ 성능 부족 |
| **0.5 vCPU** | **10~20 RPS** | ✔️ 평시·야간·점심 모두 커버 |
| 1 vCPU | 25~40 RPS | ❌ 비용 2배, 필요 이상 |
| 2 vCPU | 50~80 RPS | ❌ 과도한 스펙 |

→ **0.5 vCPU가 비용·성능의 최적 균형점**

---

### **4. 도메인 특성 상 CPU보다 I/O가 병목**

- **Order 서비스**
    - 이벤트 발행 후 즉시 응답 → CPU 사용량 낮음
- **Stock / Payment**
    - DB I/O 중심 → CPU 증가해도 효과 미미
- 즉, CPU 스펙을 올리는 **Scale-up보다 Task 분산(Scale-out)이 훨씬 효율적**

---

### **5. 블랙프라이데이 피크 200RPS는 Task 개수 확장으로 해결**

- 200 RPS / 20 RPS(Task 1) = **10개 필요**
- AZ + 장애 대비 → **12~14개 권장**
- 스펙 자체를 업그레이드할 필요 없이 **Task 수만 늘리면 해결됨**

---

### **6. 피크 스케일링 비용도 충분히 경제적**

- Task 1개 비용: **약 0.15 USD/hour**
- 추가 Task 10개 × 24시간 = **36 USD(48,000원)**
- 블랙프라이데이 매출 손실 리스크는 수십억~수백억
- SLA 위약금만 해도 **25만원(월 매출 10%)**

→ **4.8만 원 투자로 SLA·매출 리스크를 모두 제거하는 구조**

---

### **7. 스펙 업그레이드보다 스케일아웃이 더 유연하고 안전**

- CPU/vCPU를 키우면 전체 Task 수가 줄어 **AZ 장애 시 리스크 증가**
- 반대로 다수 Task는:
    - AZ 장애에도 영향 최소화
    - 트래픽 분산 유리
    - 가격도 더 저렴

---

### ✔ **최종 결론**

**0.5 vCPU / 1GB는 다음 5가지를 모두 충족합니다.**

1. 실측 성능으로 검증된 20RPS 안정 처리
2. 평시 트래픽은 2개 Task로 충분
3. CPU 과할당 없이 비용 최소화
4. 도메인 특성과 병목 구조에 최적화
5. 피크(200RPS)는 Task 확장으로 저비용 대응 가능

→ **따라서 0.5 vCPU 1GB + 최소 2개 Task(평시) + 12~14개 Task(피크)** 전략이
SLA·비용·안정성을 모두 만족한다고 판단하였습니다.


